{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81d35fc6",
   "metadata": {},
   "source": [
    "# Data preparation from COCO dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0754de9",
   "metadata": {},
   "source": [
    "Before extracting data, we should first import some necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "705277a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import requests\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9d3d07",
   "metadata": {},
   "source": [
    "Then we can go into the dataset directory and start making some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bd02b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34af5ae7",
   "metadata": {},
   "source": [
    "First, we should download the zip files of the COCO dataset and unzip them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84779f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://images.cocodataset.org/zips/train2017.zip\n",
    "!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
    "!unzip train2017.zip\n",
    "!unzip annotations_trainval2017.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edd2641",
   "metadata": {},
   "source": [
    "After downloading and unzipping files, we can use the API provided by the COCO dataset to extract specific images containing the type of object we want to classify.\n",
    "\n",
    "If we want to classify more than two classes, we must ensure that each class has a similar amount of data, so that the model can learn better. So we extract the image IDs of each object separately and add them equally to the final set of image IDs.\n",
    "\n",
    "Of course, if you request more data than the coco data set has, there will be some problems. At the same time, some data augumentation should also be done to avoid excessive differences in the amount of data of each class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b892a2",
   "metadata": {},
   "source": [
    "## Single class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dbdb4f",
   "metadata": {},
   "source": [
    "Here, we will demonstrate a single class extraction process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f67cb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=22.69s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# Use coco api to get informations in annotations json file\n",
    "coco=COCO('annotations/instances_train2017.json')\n",
    "\n",
    "# Get the class Ids from the classes we want to extract\n",
    "catIds = coco.getCatIds(catNms=['person'])\n",
    "\n",
    "# Extract the image IDs for each object separately and store them into a 2D list\n",
    "imgIds = [[] for _ in range(len(catIds))]\n",
    "for i in range(len(catIds)):\n",
    "    imgIds[i] += coco.getImgIds(catIds=catIds[i])\n",
    "\n",
    "# Define the total number of datas we want to extract\n",
    "num_data = 100\n",
    "\n",
    "# Add each object's image ID equally to the final set of image IDs and load the image info into a list 'images'\n",
    "num_class = len(catIds)\n",
    "helpset = set()\n",
    "imgIds_final = []\n",
    "count = 0\n",
    "while count < num_data:\n",
    "    while imgIds[count%num_class][0] in helpset:\n",
    "        imgIds[count%num_class].pop(0)\n",
    "    curr_id = imgIds[count%num_class].pop(0)\n",
    "    helpset.add(curr_id)\n",
    "    imgIds_final.append(curr_id)\n",
    "    count+=1\n",
    "images = coco.loadImgs(imgIds_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e88c6e",
   "metadata": {},
   "source": [
    "Then we need to make a reference chart to convert coco's class labels into our own class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62363567",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = {\n",
    "    1:1,  #coco's person id=1, custom person id = 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08acdb8d",
   "metadata": {},
   "source": [
    "Finally, we can use the API provided by the COCO dataset to get the images and necessary annotations, and save them in the corresponding directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44d9af6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:55<00:00,  1.16s/it]\n"
     ]
    }
   ],
   "source": [
    "# For each iteration, an image and a corresponding annotation will be saved\n",
    "for i in tqdm(range(len(images))):\n",
    "    im = images[i]\n",
    "    \n",
    "    # Request image from coco_url and save it\n",
    "    img_data = requests.get(im['coco_url']).content\n",
    "    with open('image_train/' + str(i) + '.jpg', 'wb') as handler:\n",
    "        handler.write(img_data)\n",
    "    \n",
    "    # Define a dictionary to store annotations\n",
    "    img_inf = {\n",
    "        'boxes': [],\n",
    "        'labels': [],\n",
    "        'masks': []\n",
    "    }\n",
    "    \n",
    "    # Get annotations corresponding to the image\n",
    "    annIds = []\n",
    "    for catId in catIds:\n",
    "        annIds += coco.getAnnIds(imgIds=im['id'], catIds=catId, iscrowd=None)\n",
    "    anns = coco.loadAnns(annIds)\n",
    "    \n",
    "    # Store annotations in the format required by the model\n",
    "    for ann in anns:\n",
    "        a_box = ann['bbox']\n",
    "        box = [a_box[0],a_box[1],a_box[0]+a_box[2],a_box[1]+a_box[3]]\n",
    "        img_inf[\"boxes\"].append(box)\n",
    "        label = reference[ann['category_id']]\n",
    "        img_inf[\"labels\"].append(label)\n",
    "        mask = coco.annToMask(ann)\n",
    "        img_inf[\"masks\"].append(mask)\n",
    "    \n",
    "    # Convert annotations into np.array\n",
    "    img_inf[\"boxes\"] = np.array(img_inf[\"boxes\"])\n",
    "    img_inf[\"labels\"] = np.array(img_inf[\"labels\"])\n",
    "    img_inf[\"masks\"] = np.array(img_inf[\"masks\"])\n",
    "    \n",
    "    # Save the annotation in a NPY file\n",
    "    np.save('annotation_train/' + str(i) + '.npy', img_inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1281cdae",
   "metadata": {},
   "source": [
    "## Multiple classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c525dd37",
   "metadata": {},
   "source": [
    "We can also do it with multiple classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce26b3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=24.13s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# Use coco api to get informations in annotations json file\n",
    "coco=COCO('annotations/instances_train2017.json')\n",
    "\n",
    "# Get the class Ids from the classes we want to extract\n",
    "catIds = coco.getCatIds(catNms=['person','cat','bird'])\n",
    "\n",
    "# Extract the image IDs for each object separately and store them into a 2D list\n",
    "imgIds = [[] for _ in range(len(catIds))]\n",
    "for i in range(len(catIds)):\n",
    "    imgIds[i] += coco.getImgIds(catIds=catIds[i])\n",
    "\n",
    "# Define the total number of datas we want to extract\n",
    "num_data = 20\n",
    "\n",
    "# Add each object's image ID equally to the final set of image IDs and load the image info into a list 'images'\n",
    "num_class = len(catIds)\n",
    "helpset = set()\n",
    "imgIds_final = []\n",
    "count = 0\n",
    "while count < num_data:\n",
    "    while imgIds[count%num_class][0] in helpset:\n",
    "        imgIds[count%num_class].pop(0)\n",
    "    curr_id = imgIds[count%num_class].pop(0)\n",
    "    helpset.add(curr_id)\n",
    "    imgIds_final.append(curr_id)\n",
    "    count+=1\n",
    "images = coco.loadImgs(imgIds_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cd9d731",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = {\n",
    "    1:1,  #coco's person id=1, custom person id = 1\n",
    "    17:2, #coco's cat id=1, custom cat id = 1\n",
    "    16:3  #coco's bird id=1, custom bird's id = 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e527636c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir image_train_multi annotation_train_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c68a95d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:21<00:00,  1.05s/it]\n"
     ]
    }
   ],
   "source": [
    "# For each iteration, an image and a corresponding annotation will be saved\n",
    "for i in tqdm(range(len(images))):\n",
    "    im = images[i]\n",
    "    \n",
    "    # Request image from coco_url and save it\n",
    "    img_data = requests.get(im['coco_url']).content\n",
    "    with open('image_train_multi/' + str(i) + '.jpg', 'wb') as handler:\n",
    "        handler.write(img_data)\n",
    "    \n",
    "    # Define a dictionary to store annotations\n",
    "    img_inf = {\n",
    "        'boxes': [],\n",
    "        'labels': [],\n",
    "        'masks': []\n",
    "    }\n",
    "    \n",
    "    # Get annotations corresponding to the image\n",
    "    annIds = []\n",
    "    for catId in catIds:\n",
    "        annIds += coco.getAnnIds(imgIds=im['id'], catIds=catId, iscrowd=None)\n",
    "    anns = coco.loadAnns(annIds)\n",
    "    \n",
    "    # Store annotations in the format required by the model\n",
    "    for ann in anns:\n",
    "        a_box = ann['bbox']\n",
    "        box = [a_box[0],a_box[1],a_box[0]+a_box[2],a_box[1]+a_box[3]]\n",
    "        img_inf[\"boxes\"].append(box)\n",
    "        label = reference[ann['category_id']]\n",
    "        img_inf[\"labels\"].append(label)\n",
    "        mask = coco.annToMask(ann)\n",
    "        img_inf[\"masks\"].append(mask)\n",
    "    \n",
    "    # Convert annotations into np.array\n",
    "    img_inf[\"boxes\"] = np.array(img_inf[\"boxes\"])\n",
    "    img_inf[\"labels\"] = np.array(img_inf[\"labels\"])\n",
    "    img_inf[\"masks\"] = np.array(img_inf[\"masks\"])\n",
    "    \n",
    "    # Save the annotation in a NPY file\n",
    "    np.save('annotation_train_multi/' + str(i) + '.npy', img_inf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
